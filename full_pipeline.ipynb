{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7afd44ed",
   "metadata": {},
   "source": [
    "## DOCUMENT PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4436b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Full hybrid PDF extraction pipeline:\n",
    "- PDF operator analysis (text vs images)\n",
    "- PyPDF extraction (fast)\n",
    "- Tesseract OCR (medium)\n",
    "- Docling (slow, high-quality) or optional transformer-based OCR fallback\n",
    "- Composite quality scorer to decide escalation\n",
    "\n",
    "Example run at bottom\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import io\n",
    "import math\n",
    "import tempfile\n",
    "import pytesseract\n",
    "import concurrent.futures\n",
    "from pypdf import PdfReader\n",
    "from functools import lru_cache\n",
    "from typing import Tuple, Dict, List\n",
    "from pdf2image import convert_from_path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    import docling\n",
    "    HAS_DOCLING = True\n",
    "except Exception:\n",
    "    HAS_DOCLING = False\n",
    "\n",
    "try:\n",
    "    from wordfreq import zipf_frequency\n",
    "    HAS_WORD_FREQ = True\n",
    "except Exception:\n",
    "    HAS_WORD_FREQ = False\n",
    "\n",
    "try:\n",
    "    from langdetect import detect_langs\n",
    "    HAS_LANGDETECT = True\n",
    "except Exception:\n",
    "    HAS_LANGDETECT = False\n",
    "\n",
    "# Optional perplexity using transformers (slow)\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "    import torch\n",
    "    HAS_TRANSFORMERS = True\n",
    "except Exception:\n",
    "    HAS_TRANSFORMERS = False\n",
    "\n",
    "\n",
    "#########################\n",
    "# 1) PDF structure analysis\n",
    "#########################\n",
    "def analyze_pdf_ops(filepath: str) -> List[Tuple[int, int, int]]:\n",
    "    \"\"\"\n",
    "    Return a list of tuples (page_number, text_ops, image_ops)\n",
    "    \"\"\"\n",
    "    reader = PdfReader(filepath)\n",
    "    ops_summary = []\n",
    "\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        # Get raw content stream(s)\n",
    "        contents = page.get_contents()\n",
    "        stream_data = b\"\"\n",
    "        if contents:\n",
    "            # pypdf may return a single object or a list\n",
    "            if isinstance(contents, list):\n",
    "                for c in contents:\n",
    "                    try:\n",
    "                        stream_data += c.get_data()\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            else:\n",
    "                try:\n",
    "                    stream_data = contents.get_data()\n",
    "                except Exception:\n",
    "                    stream_data = b\"\"\n",
    "\n",
    "        # count common text operators and image \"Do\" operator\n",
    "        text_ops = (\n",
    "            stream_data.count(b\"Tj\")\n",
    "            + stream_data.count(b\"TJ\")\n",
    "            + stream_data.count(b\"Tf\")\n",
    "            + stream_data.count(b\"Td\")\n",
    "            + stream_data.count(b\"TD\")\n",
    "            + stream_data.count(b\"Tm\")\n",
    "            + stream_data.count(b\"T*\")\n",
    "        )\n",
    "        image_ops = stream_data.count(b\"Do\")\n",
    "        ops_summary.append((i + 1, text_ops, image_ops))\n",
    "\n",
    "    return ops_summary\n",
    "\n",
    "\n",
    "#########################\n",
    "# 2) Extract using PyPDF (born-digital)\n",
    "#########################\n",
    "def extract_text_pypdf(filepath: str, page_index: int) -> str:\n",
    "    reader = PdfReader(filepath)\n",
    "    page = reader.pages[page_index]\n",
    "    text = page.extract_text() or \"\"\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "#########################\n",
    "# 3) OCR functions\n",
    "#########################\n",
    "def ocr_tesseract_image(image) -> str:\n",
    "    \"\"\"Run pytesseract on a PIL image object\"\"\"\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "\n",
    "def ocr_docling_image(image) -> str:\n",
    "    \"\"\"Run docling (or fallback) on a PIL image object.\n",
    "    This function expects docling to be installed & configured.\n",
    "    If not available, returns None.\n",
    "    \"\"\"\n",
    "    if not HAS_DOCLING:\n",
    "        raise RuntimeError(\"Docling is not available in this environment.\")\n",
    "    # Docling usage will depend on its API — below is a placeholder example.\n",
    "    # Replace with the actual docling invocation in your environment.\n",
    "    # Example (pseudocode):\n",
    "    # result = docling.ocr_image(image)\n",
    "    # return result[\"text\"]\n",
    "    return docling.ocr_image_to_text(image)\n",
    "\n",
    "\n",
    "#########################\n",
    "# 4) Quality evaluation\n",
    "#########################\n",
    "RE_BAD_CHAR = re.compile(r\"[^\\x00-\\x7F\\u00A0-\\u017F]\")  # many non-ascii/unusual chars\n",
    "RE_WORD = re.compile(r\"[A-Za-zÀ-ÖØ-öø-ÿ'’-]{2,}\")  # words with accents, hyphens\n",
    "\n",
    "def garbage_ratio(text: str) -> float:\n",
    "    if not text:\n",
    "        return 1.0\n",
    "    total = len(text)\n",
    "    bad = len(RE_BAD_CHAR.findall(text))\n",
    "    return bad / max(1, total)\n",
    "\n",
    "\n",
    "def word_dictionary_fraction(text: str) -> float:\n",
    "    \"\"\"\n",
    "    A heuristic: fraction of words that appear to be real based on wordfreq zipf frequency.\n",
    "    If wordfreq not available, fall back to a simple heuristic (letters-only words / total words).\n",
    "    \"\"\"\n",
    "    words = RE_WORD.findall(text)\n",
    "    if not words:\n",
    "        return 0.0\n",
    "\n",
    "    if HAS_WORD_FREQ:\n",
    "        valid = 0\n",
    "        for w in words:\n",
    "            # zipf_frequency returns a score -4..7; treat > 3.0 as likely real/common word\n",
    "            if zipf_frequency(w.lower(), \"en\") > 1.5:\n",
    "                valid += 1\n",
    "        return valid / len(words)\n",
    "    else:\n",
    "        # fallback: count words that have >2 letters and at least one vowel\n",
    "        def looks_real(w):\n",
    "            return (len(w) > 2) and (re.search(r\"[aeiouyAEIOUYàèéùôî]\", w) is not None)\n",
    "        valid = sum(1 for w in words if looks_real(w))\n",
    "        return valid / len(words)\n",
    "\n",
    "\n",
    "def detect_primary_language_confidence(text: str) -> float:\n",
    "    \"\"\"\n",
    "    Returns a confidence-like score (0..1) that language detection is stable / strong.\n",
    "    Uses langdetect if available.\n",
    "    \"\"\"\n",
    "    if not text or not HAS_LANGDETECT:\n",
    "        return 0.0\n",
    "\n",
    "    try:\n",
    "        langs = detect_langs(text)\n",
    "        if not langs:\n",
    "            return 0.0\n",
    "        top = langs[0]\n",
    "        # top.prob (0..1)\n",
    "        return float(top.prob)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def perplexity_score(text: str, model_name=\"gpt2\") -> float:\n",
    "    \"\"\"\n",
    "    Optional: compute (normalized) perplexity using a small transformer model.\n",
    "    Returns a score in range (0..1) where 1 means low perplexity (good), 0 means high perplexity (bad).\n",
    "    If transformers not available, return 0.5 (neutral).\n",
    "    \"\"\"\n",
    "    if not HAS_TRANSFORMERS or not text:\n",
    "        return 0.5\n",
    "\n",
    "    # Keep short for speed\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        model.eval()\n",
    "        if torch.cuda.is_available():\n",
    "            model.to(\"cuda\")\n",
    "\n",
    "        enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "        if torch.cuda.is_available():\n",
    "            enc = {k: v.to(\"cuda\") for k, v in enc.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**enc, labels=enc[\"input_ids\"])\n",
    "            # average negative log-likelihood per token\n",
    "            loss = outputs.loss.item()\n",
    "            ppl = math.exp(loss)\n",
    "            # normalize: for our use, convert to 0..1 with a stabilizing mapping\n",
    "            # lower ppl -> better -> produce higher score\n",
    "            score = 1.0 / (1.0 + math.log(1.0 + ppl))\n",
    "            return float(score)\n",
    "    except Exception:\n",
    "        return 0.5\n",
    "\n",
    "\n",
    "def evaluate_text_quality(text: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Return a dict with component scores and a combined 'score' (0..1).\n",
    "    Higher is better.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return {\n",
    "            \"garbage_ratio\": 1.0,\n",
    "            \"dictionary_fraction\": 0.0,\n",
    "            \"lang_conf\": 0.0,\n",
    "            \"perplexity_score\": 0.5,\n",
    "            \"score\": 0.0,\n",
    "        }\n",
    "\n",
    "    g = garbage_ratio(text)  # lower better\n",
    "    d = word_dictionary_fraction(text)  # higher better\n",
    "    l = detect_primary_language_confidence(text)  # higher better\n",
    "    p = perplexity_score(text)  # higher better\n",
    "\n",
    "    # normalize garbage to 0..1 where 1 = perfect (no garbage)\n",
    "    garbage_ok = max(0.0, 1.0 - g)\n",
    "\n",
    "    # Compose weighted score\n",
    "    score = (0.35 * d) + (0.25 * garbage_ok) + (0.25 * p) + (0.15 * l)\n",
    "    score = max(0.0, min(1.0, score))\n",
    "\n",
    "    return {\n",
    "        \"garbage_ratio\": g,\n",
    "        \"dictionary_fraction\": d,\n",
    "        \"lang_conf\": l,\n",
    "        \"perplexity_score\": p,\n",
    "        \"score\": score,\n",
    "    }\n",
    "\n",
    "\n",
    "#########################\n",
    "# 5) Page-level processing logic\n",
    "#########################\n",
    "def process_page(filepath: str, page_index: int, dpi: int = 300,\n",
    "                 min_text_ops_for_born_digital: int = 10,\n",
    "                 tesseract_threshold: float = 0.45,\n",
    "                 docling_threshold: float = 0.30) -> Dict:\n",
    "    \"\"\"\n",
    "    Process a single page:\n",
    "      - If operator analysis shows many text ops -> use PyPDF text\n",
    "      - Else convert page to image, run Tesseract, score it\n",
    "      - If score low -> run Docling (or slow fallback)\n",
    "    Returns dict with keys: 'final_text', 'extraction_method', 'scores', 'pageno'\n",
    "    \"\"\"\n",
    "    # 1) operator-level check\n",
    "    reader = PdfReader(filepath)\n",
    "    page = reader.pages[page_index]\n",
    "    contents = page.get_contents()\n",
    "    stream_data = b\"\"\n",
    "    if contents:\n",
    "        if isinstance(contents, list):\n",
    "            for c in contents:\n",
    "                try:\n",
    "                    stream_data += c.get_data()\n",
    "                except Exception:\n",
    "                    pass\n",
    "        else:\n",
    "            try:\n",
    "                stream_data = contents.get_data()\n",
    "            except Exception:\n",
    "                stream_data = b\"\"\n",
    "    text_ops = (\n",
    "        stream_data.count(b\"Tj\")\n",
    "        + stream_data.count(b\"TJ\")\n",
    "        + stream_data.count(b\"Tf\")\n",
    "        + stream_data.count(b\"Td\")\n",
    "        + stream_data.count(b\"TD\")\n",
    "        + stream_data.count(b\"Tm\")\n",
    "        + stream_data.count(b\"T*\")\n",
    "    )\n",
    "    image_ops = stream_data.count(b\"Do\")\n",
    "\n",
    "    # 2) If many text ops -> born-digital\n",
    "    if text_ops >= min_text_ops_for_born_digital and text_ops > image_ops:\n",
    "        extracted = page.extract_text() or \"\"\n",
    "        scores = evaluate_text_quality(extracted)\n",
    "        return {\n",
    "            \"pageno\": page_index + 1,\n",
    "            \"final_text\": extracted,\n",
    "            \"extraction_method\": \"pypdf-born-digital\",\n",
    "            \"scores\": scores,\n",
    "            \"text_ops\": text_ops,\n",
    "            \"image_ops\": image_ops,\n",
    "        }\n",
    "\n",
    "    # 3) Otherwise, produce page image and OCR with Tesseract\n",
    "    images = convert_from_path(filepath, first_page=page_index + 1, last_page=page_index + 1, dpi=dpi)\n",
    "    if not images:\n",
    "        return {\n",
    "            \"pageno\": page_index + 1,\n",
    "            \"final_text\": \"\",\n",
    "            \"extraction_method\": \"empty-page\",\n",
    "            \"scores\": {\"score\": 0.0},\n",
    "            \"text_ops\": text_ops,\n",
    "            \"image_ops\": image_ops,\n",
    "        }\n",
    "    img = images[0]\n",
    "\n",
    "    # If there is some extractable text (eg header), keep it to combine later\n",
    "    pypdf_text = page.extract_text() or \"\"\n",
    "\n",
    "    # Tesseract (fast)\n",
    "    tesseract_text = ocr_tesseract_image(img)\n",
    "    t_scores = evaluate_text_quality(tesseract_text)\n",
    "\n",
    "    # If Tesseract quality is acceptable, use it\n",
    "    if t_scores[\"score\"] >= tesseract_threshold:\n",
    "        # combine with pypdf small header if it exists and is not redundant\n",
    "        combined = (pypdf_text + \"\\n\" + tesseract_text).strip()\n",
    "        return {\n",
    "            \"pageno\": page_index + 1,\n",
    "            \"final_text\": combined,\n",
    "            \"extraction_method\": \"tesseract\",\n",
    "            \"scores\": t_scores,\n",
    "            \"text_ops\": text_ops,\n",
    "            \"image_ops\": image_ops,\n",
    "        }\n",
    "\n",
    "    # 4) Escalate to Docling / high-quality OCR\n",
    "    # Try docling if available\n",
    "    slow_text = None\n",
    "    if HAS_DOCLING:\n",
    "        try:\n",
    "            slow_text = ocr_docling_image(img)\n",
    "        except Exception as e:\n",
    "            slow_text = None\n",
    "\n",
    "    # If docling not available, try transformer-based model (if present)\n",
    "    if slow_text is None and HAS_TRANSFORMERS:\n",
    "        try:\n",
    "            # Example: apply a transformer OCR or vision model - pseudo\n",
    "            # NOTE: Implement actual model-specific call here if you set it up.\n",
    "            # For illustration only; many vision models take images differently.\n",
    "            from PIL import Image\n",
    "            # here we'd call a model to get better OCR - placeholder:\n",
    "            slow_text = ocr_tesseract_image(img)  # fallback if no better model available\n",
    "        except Exception:\n",
    "            slow_text = None\n",
    "\n",
    "    # Evaluate slow_text if we obtained one\n",
    "    if slow_text:\n",
    "        s_scores = evaluate_text_quality(slow_text)\n",
    "        # If slow_text improved score, return it; else keep tesseract\n",
    "        if s_scores[\"score\"] >= t_scores[\"score\"] or s_scores[\"score\"] >= docling_threshold:\n",
    "            combined = (pypdf_text + \"\\n\" + slow_text).strip()\n",
    "            return {\n",
    "                \"pageno\": page_index + 1,\n",
    "                \"final_text\": combined,\n",
    "                \"extraction_method\": \"docling\" if HAS_DOCLING else \"transformer_slow\",\n",
    "                \"scores\": s_scores,\n",
    "                \"text_ops\": text_ops,\n",
    "                \"image_ops\": image_ops,\n",
    "            }\n",
    "\n",
    "    # 5) fallback: return Tesseract result (best we have)\n",
    "    return {\n",
    "        \"pageno\": page_index + 1,\n",
    "        \"final_text\": (pypdf_text + \"\\n\" + tesseract_text).strip(),\n",
    "        \"extraction_method\": \"tesseract_fallback\",\n",
    "        \"scores\": t_scores,\n",
    "        \"text_ops\": text_ops,\n",
    "        \"image_ops\": image_ops,\n",
    "    }\n",
    "\n",
    "\n",
    "#########################\n",
    "# 6) Process entire PDF\n",
    "#########################\n",
    "\n",
    "def process_pdf(filepath: str, dpi: int = 150, max_pages: int = None, \n",
    "               max_workers: int = 4, fast_mode: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Optimized PDF processing with parallel execution and batch operations.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(filepath)\n",
    "    n_pages = len(reader.pages)\n",
    "    pages_to_process = range(n_pages) if max_pages is None else range(min(n_pages, max_pages))\n",
    "\n",
    "    # FAST PATH: For large PDFs, use simplified processing\n",
    "    if n_pages > 50 and fast_mode:\n",
    "        return process_large_pdf_fast(filepath, dpi, max_pages, max_workers)\n",
    "\n",
    "    # Standard processing for smaller PDFs\n",
    "    needs_ocr_per_page = analyze_pdf_needs_ocr(filepath, n_pages)\n",
    "    ocr_page_indices = [i for i, needs_ocr in enumerate(needs_ocr_per_page) if needs_ocr]\n",
    "    all_images = []\n",
    "    \n",
    "    if ocr_page_indices:\n",
    "        all_images = convert_from_path(\n",
    "            filepath, \n",
    "            dpi=dpi,\n",
    "            grayscale=True,\n",
    "            thread_count=4,\n",
    "            first_page=1,\n",
    "            last_page=n_pages\n",
    "        )\n",
    "    \n",
    "    image_map = {}\n",
    "    if all_images:\n",
    "        for i in ocr_page_indices:\n",
    "            if i < len(all_images):\n",
    "                image_map[i] = all_images[i]\n",
    "\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_page = {\n",
    "            executor.submit(\n",
    "                process_page_optimized, \n",
    "                filepath, \n",
    "                i, \n",
    "                dpi, \n",
    "                image_map.get(i),\n",
    "                fast_mode\n",
    "            ): i \n",
    "            for i in pages_to_process\n",
    "        }\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(future_to_page):\n",
    "            page_index = future_to_page[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Page {page_index + 1} failed: {e}\")\n",
    "                results.append(create_fallback_result(page_index))\n",
    "\n",
    "    results.sort(key=lambda x: x[\"pageno\"])\n",
    "    \n",
    "    summary = {\n",
    "        \"total_pages\": n_pages,\n",
    "        \"processed_pages\": len(results),\n",
    "        \"born_digital_pages\": sum(1 for p in results if p[\"extraction_method\"].startswith(\"pypdf\")),\n",
    "        \"tesseract_pages\": sum(1 for p in results if p[\"extraction_method\"].startswith(\"tesseract\")),\n",
    "        \"docling_pages\": sum(1 for p in results if p[\"extraction_method\"].startswith(\"docling\")),\n",
    "        \"error_pages\": sum(1 for p in results if p[\"extraction_method\"] == \"error\"),\n",
    "    }\n",
    "\n",
    "    return {\"pages\": results, \"summary\": summary}\n",
    "\n",
    "def process_large_pdf_fast(filepath: str, dpi: int = 150, max_pages: int = None, \n",
    "                          max_workers: int = 4) -> Dict:\n",
    "    \"\"\"\n",
    "    Ultra-fast processing for large PDFs (>50 pages)\n",
    "    \"\"\"\n",
    "    reader = PdfReader(filepath)\n",
    "    n_pages = len(reader.pages)\n",
    "    pages_to_process = range(n_pages) if max_pages is None else range(min(n_pages, max_pages))\n",
    "\n",
    "    # Quick operator analysis\n",
    "    operator_summary = analyze_pdf_ops_fast(filepath)\n",
    "    \n",
    "    # Batch convert all images at once\n",
    "    all_images = convert_from_path(\n",
    "        filepath, \n",
    "        dpi=dpi,\n",
    "        grayscale=True,\n",
    "        thread_count=4\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_page = {\n",
    "            executor.submit(\n",
    "                process_page_fast, \n",
    "                filepath, \n",
    "                i, \n",
    "                operator_summary[i] if i < len(operator_summary) else (i+1, 0, 0),\n",
    "                all_images[i] if i < len(all_images) else None\n",
    "            ): i \n",
    "            for i in pages_to_process\n",
    "        }\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(future_to_page):\n",
    "            page_index = future_to_page[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Page {page_index + 1} failed: {e}\")\n",
    "                results.append(create_fallback_result(page_index))\n",
    "\n",
    "    results.sort(key=lambda x: x[\"pageno\"])\n",
    "    \n",
    "    summary = {\n",
    "        \"total_pages\": n_pages,\n",
    "        \"processed_pages\": len(results),\n",
    "        \"born_digital_pages\": sum(1 for p in results if \"pypdf\" in p[\"extraction_method\"]),\n",
    "        \"tesseract_pages\": sum(1 for p in results if \"tesseract\" in p[\"extraction_method\"]),\n",
    "        \"mode\": \"fast_large_pdf\",\n",
    "    }\n",
    "\n",
    "    return {\"pages\": results, \"summary\": summary}\n",
    "\n",
    "def process_page_fast(filepath: str, page_index: int, operator_info: Tuple[int, int, int], \n",
    "                     pre_converted_image=None) -> Dict:\n",
    "    \"\"\"\n",
    "    Ultra-fast page processing for large PDFs\n",
    "    \"\"\"\n",
    "    reader = PdfReader(filepath)\n",
    "    page = reader.pages[page_index]\n",
    "    page_num, text_ops, image_ops = operator_info\n",
    "    \n",
    "    # 1) Try PyPDF first (fastest)\n",
    "    pypdf_text = page.extract_text() or \"\"\n",
    "    \n",
    "    # Simple heuristic: if we found reasonable text, use it\n",
    "    if len(pypdf_text.strip()) > 100 or text_ops > 5:\n",
    "        return {\n",
    "            \"pageno\": page_index + 1,\n",
    "            \"final_text\": pypdf_text,\n",
    "            \"extraction_method\": \"pypdf-born-digital\",\n",
    "            \"scores\": {\"score\": 0.8},\n",
    "            \"text_ops\": text_ops,\n",
    "            \"image_ops\": image_ops,\n",
    "        }\n",
    "    \n",
    "    # 2) OCR path - only if we have pre-converted image\n",
    "    if pre_converted_image is not None:\n",
    "        tesseract_text = ocr_tesseract_image(pre_converted_image)\n",
    "        combined_text = (pypdf_text + \"\\n\" + tesseract_text).strip()\n",
    "        \n",
    "        return {\n",
    "            \"pageno\": page_index + 1,\n",
    "            \"final_text\": combined_text,\n",
    "            \"extraction_method\": \"tesseract_fast\",\n",
    "            \"scores\": {\"score\": 0.5},\n",
    "            \"text_ops\": text_ops,\n",
    "            \"image_ops\": image_ops,\n",
    "        }\n",
    "    \n",
    "    # 3) Fallback: minimal text extraction only\n",
    "    return {\n",
    "        \"pageno\": page_index + 1,\n",
    "        \"final_text\": pypdf_text,\n",
    "        \"extraction_method\": \"pypdf_fallback\",\n",
    "        \"scores\": {\"score\": 0.3},\n",
    "        \"text_ops\": text_ops,\n",
    "        \"image_ops\": image_ops,\n",
    "    }\n",
    "\n",
    "def process_page_optimized(filepath: str, page_index: int, dpi: int = 150, \n",
    "                          pre_converted_image=None, fast_mode: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Optimized page processing using pre-converted images\n",
    "    \"\"\"\n",
    "    reader = PdfReader(filepath)\n",
    "    page = reader.pages[page_index]\n",
    "    \n",
    "    # 1) Try PyPDF first\n",
    "    pypdf_text = page.extract_text() or \"\"\n",
    "    \n",
    "    if len(pypdf_text.strip()) > 200:\n",
    "        scores = evaluate_text_quality_fast(pypdf_text) if fast_mode else evaluate_text_quality(pypdf_text)\n",
    "        return {\n",
    "            \"pageno\": page_index + 1,\n",
    "            \"final_text\": pypdf_text,\n",
    "            \"extraction_method\": \"pypdf-born-digital\",\n",
    "            \"scores\": scores,\n",
    "            \"text_ops\": 1,\n",
    "            \"image_ops\": 0,\n",
    "        }\n",
    "    \n",
    "    # 2) OCR path\n",
    "    if pre_converted_image:\n",
    "        img = pre_converted_image\n",
    "    else:\n",
    "        images = convert_from_path(\n",
    "            filepath, \n",
    "            first_page=page_index + 1, \n",
    "            last_page=page_index + 1, \n",
    "            dpi=dpi,\n",
    "            grayscale=True\n",
    "        )\n",
    "        img = images[0] if images else None\n",
    "    \n",
    "    if not img:\n",
    "        return create_fallback_result(page_index)\n",
    "    \n",
    "    tesseract_text = ocr_tesseract_image(img)\n",
    "    combined_text = (pypdf_text + \"\\n\" + tesseract_text).strip()\n",
    "    \n",
    "    if fast_mode:\n",
    "        scores = evaluate_text_quality_fast(combined_text)\n",
    "        return {\n",
    "            \"pageno\": page_index + 1,\n",
    "            \"final_text\": combined_text,\n",
    "            \"extraction_method\": \"tesseract_fast\",\n",
    "            \"scores\": scores,\n",
    "            \"text_ops\": 0,\n",
    "            \"image_ops\": 1,\n",
    "        }\n",
    "    else:\n",
    "        scores = evaluate_text_quality(combined_text)\n",
    "        return {\n",
    "            \"pageno\": page_index + 1,\n",
    "            \"final_text\": combined_text,\n",
    "            \"extraction_method\": \"tesseract\",\n",
    "            \"scores\": scores,\n",
    "            \"text_ops\": 0,\n",
    "            \"image_ops\": 1,\n",
    "        }\n",
    "\n",
    "def analyze_pdf_needs_ocr(filepath: str, n_pages: int) -> List[bool]:\n",
    "    \"\"\"Quick analysis to determine which pages need OCR\"\"\"\n",
    "    reader = PdfReader(filepath)\n",
    "    needs_ocr = []\n",
    "    \n",
    "    for i in range(min(n_pages, 1000)):\n",
    "        try:\n",
    "            page = reader.pages[i]\n",
    "            text = page.extract_text() or \"\"\n",
    "            needs_ocr.append(len(text.strip()) < 100)\n",
    "        except:\n",
    "            needs_ocr.append(True)\n",
    "    \n",
    "    return needs_ocr\n",
    "\n",
    "def analyze_pdf_ops_fast(filepath: str) -> List[Tuple[int, int, int]]:\n",
    "    \"\"\"Faster operator analysis\"\"\"\n",
    "    reader = PdfReader(filepath)\n",
    "    ops_summary = []\n",
    "    \n",
    "    for i, page in enumerate(reader.pages):\n",
    "        try:\n",
    "            text = page.extract_text() or \"\"\n",
    "            text_ops = 1 if len(text.strip()) > 50 else 0\n",
    "            \n",
    "            contents = page.get_contents()\n",
    "            image_ops = 0\n",
    "            if contents:\n",
    "                stream_data = b\"\"\n",
    "                if isinstance(contents, list):\n",
    "                    for c in contents[:2]:\n",
    "                        try:\n",
    "                            stream_data += c.get_data()[:1000]\n",
    "                        except:\n",
    "                            pass\n",
    "                else:\n",
    "                    try:\n",
    "                        stream_data = contents.get_data()[:1000]\n",
    "                    except:\n",
    "                        pass\n",
    "                image_ops = stream_data.count(b\"Do\")\n",
    "            \n",
    "            ops_summary.append((i + 1, text_ops, image_ops))\n",
    "        except:\n",
    "            ops_summary.append((i + 1, 0, 1))\n",
    "    \n",
    "    return ops_summary\n",
    "\n",
    "def evaluate_text_quality_fast(text: str) -> Dict[str, float]:\n",
    "    \"\"\"Fast quality assessment\"\"\"\n",
    "    if not text:\n",
    "        return {\"score\": 0.0}\n",
    "    \n",
    "    total_chars = len(text)\n",
    "    if total_chars == 0:\n",
    "        return {\"score\": 0.0}\n",
    "        \n",
    "    non_ascii_count = len([c for c in text if ord(c) > 127])\n",
    "    garbage_ratio = non_ascii_count / total_chars\n",
    "    \n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    \n",
    "    garbage_score = max(0.0, 1.0 - garbage_ratio)\n",
    "    word_score = min(1.0, word_count / 100)\n",
    "    \n",
    "    score = (0.6 * word_score) + (0.4 * garbage_score)\n",
    "    \n",
    "    return {\n",
    "        \"score\": score,\n",
    "        \"garbage_ratio\": garbage_ratio,\n",
    "        \"word_count\": word_count,\n",
    "    }\n",
    "\n",
    "def create_fallback_result(page_index: int) -> Dict:\n",
    "    \"\"\"Create a result dict for failed pages\"\"\"\n",
    "    return {\n",
    "        \"pageno\": page_index + 1,\n",
    "        \"final_text\": \"\",\n",
    "        \"extraction_method\": \"error\",\n",
    "        \"scores\": {\"score\": 0.0},\n",
    "        \"text_ops\": 0,\n",
    "        \"image_ops\": 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb0dceb",
   "metadata": {},
   "source": [
    "## EXPERIMENT ON DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70cabbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pdf = \"sample/Le-code-du-travail-ivoirien-2023.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd0665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your 500-page PDF - this should be 10x faster\n",
    "out = process_pdf(\n",
    "    input_pdf, \n",
    "    dpi=150, \n",
    "    max_workers=10,  # Adjust based on your CPU\n",
    "    fast_mode=True   # Critical for large PDFs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEMANTIC CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acbe9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /google/embeddinggemma-300m/resolve/main/modules.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001F09D522B10>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 5267559a-cbb0-4745-8a1d-e37d4dc471e4)')' thrown while requesting HEAD https://huggingface.co/google/embeddinggemma-300m/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /google/embeddinggemma-300m/resolve/main/modules.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001F09BD49FA0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: f6ac4aff-f76f-4999-8b8c-eb6f7ebb7855)')' thrown while requesting HEAD https://huggingface.co/google/embeddinggemma-300m/resolve/main/./modules.json\n",
      "Retrying in 2s [Retry 2/5].\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"google/embeddinggemma-300m\",\n",
    "    model_kwargs={'device': 'cpu', \"trust_remote_code\": True},  # or 'cuda' if you have GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "# Create the semantic chunker\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=embedding_model,\n",
    "    breakpoint_threshold_type=\"percentile\",  # or \"standard_deviation\", \"interquartile\"\n",
    "    breakpoint_threshold_amount=95,  # adjust based on your needs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e23b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 1002 chunks with metadata.\n"
     ]
    }
   ],
   "source": [
    "# Replace your chunking logic with this to preserve page numbers\n",
    "documents = []\n",
    "\n",
    "for page in out[\"pages\"]:\n",
    "    # Create a doc for the specific page\n",
    "    page_doc = [Document(\n",
    "        page_content=page[\"final_text\"], \n",
    "        metadata={\"pageno\": page[\"pageno\"], \"source\": input_pdf}\n",
    "    )]\n",
    "    \n",
    "    page_chunks = text_splitter.split_documents(page_doc)\n",
    "    documents.extend(page_chunks)\n",
    "\n",
    "print(f\"Created {len(documents)} chunks with metadata.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBEDDING STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfeb9c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def init_opensource_embedding(model_name = \"google/embeddinggemma-300m\"):\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=model_name, # Choose a model from HuggingFace\n",
    "            model_kwargs={'device': 'cpu', \"trust_remote_code\": True},  # or 'cuda' if you have GPU\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "    print(\"HuggingFace embedding model initialized.\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abee7d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuggingFace embedding model initialized.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "embeddings = init_opensource_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b5a46",
   "metadata": {},
   "source": [
    "## VECTOR DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ba7cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec5d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.exceptions import UnexpectedResponse\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_qdrant import FastEmbedSparse, QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client.http.models import Distance, SparseVectorParams, VectorParams\n",
    "\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "\n",
    "def init_qdrant_w_gemma(collection_name, url=\"http://localhost:6333\",vector_size=768, distance_metric=models.Distance.COSINE):\n",
    "    try:\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config={\"dense\": VectorParams(size=vector_size, distance=distance_metric, on_disk=True)},\n",
    "            sparse_vectors_config={\n",
    "                \"sparse\": SparseVectorParams(index=models.SparseIndexParams(on_disk=False))\n",
    "            },\n",
    "            quantization_config={\n",
    "                \"scalar\": {\n",
    "                    \"type\": \"int8\",  # 4x smaller\n",
    "                    \"quantile\": 0.99\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        vector_store = QdrantVectorStore(\n",
    "            client=client,\n",
    "            collection_name=collection_name,\n",
    "            embedding=embeddings,\n",
    "            sparse_embedding=sparse_embeddings,\n",
    "            retrieval_mode=RetrievalMode.HYBRID,\n",
    "            vector_name=\"dense\",\n",
    "            sparse_vector_name=\"sparse\",\n",
    "        )\n",
    "        status =  {\n",
    "            \"status\": \"success\",\n",
    "            \"msg\": f\"collection {collection_name} created successfully\"\n",
    "        }\n",
    "        print(status)\n",
    "        return vector_store\n",
    "    \n",
    "    except UnexpectedResponse as e:\n",
    "        if \"already exists\" in str(e):\n",
    "            status = {\n",
    "            \"status\": \"success\",\n",
    "            \"msg\": f\"Collection '{collection_name}' already exists.\"\n",
    "            }\n",
    "            vector_store = QdrantVectorStore.from_existing_collection(\n",
    "                embedding=embeddings,\n",
    "                collection_name=collection_name,\n",
    "                url=url,\n",
    "                sparse_embedding=sparse_embeddings,\n",
    "                retrieval_mode=RetrievalMode.HYBRID,\n",
    "                vector_name=\"dense\",\n",
    "                sparse_vector_name=\"sparse\"\n",
    "            )\n",
    "            print(status)\n",
    "            return vector_store\n",
    "        else:\n",
    "            raise Exception(\"error initializing vectorstore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03548a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'success', 'msg': 'collection labor_law created successfully'}\n"
     ]
    }
   ],
   "source": [
    "vectorstore = init_qdrant_w_gemma(\"labor_law\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa34f3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "def chunks_to_documents(chunks: list[str], metadata: list[dict] = None) -> list[Document]:\n",
    "    \"\"\"Convert chunks to Documents with optional metadata.\"\"\"\n",
    "    documents = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        doc_metadata = metadata[i] if metadata else {\"index\": i}\n",
    "        documents.append(Document(page_content=chunk, metadata=doc_metadata))\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "374d661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "_ = vectorstore.add_documents(\n",
    "    documents=documents,\n",
    "    ids=[str(uuid4()) for _ in documents]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33ce3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_compressors import FlashrankRerank\n",
    "from langchain_classic.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "\n",
    "# Set up once\n",
    "reranker = FlashrankRerank()\n",
    "\n",
    "base_retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 50,\n",
    "        \"hybrid_fusion\": models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Wrap them together\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker,\n",
    "    base_retriever=base_retriever\n",
    ")\n",
    "\n",
    "# Now invoke() handles both stages automatically\n",
    "def hybrid_search(query, top_k=10):\n",
    "    results = retriever.invoke(query)\n",
    "    return results[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7de6b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/labor_law/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 12, 'relevance_score': np.float32(0.9996047), 'pageno': 9, 'source': 'sample/Le-code-du-travail-ivoirien-2023.pdf', '_id': '940e5bdb-a7a9-4f92-9180-1eb5bf52675a', '_collection_name': 'labor_law'}, page_content=\"1\\n0 \\n \\nArt. 5 \\nAucun salarié, aucune personne en formation ou en stage ne peut être sanctionné ni \\nlicencié pour avoir refusé de subir les agissements de harcèlement moral ou sexuel \\nd'un employeur, de son représentant o u de toute personne qui, abusant de l'autorité \\nque lui confèrent ses fonctions, a donné des ordres, proféré des menaces, imposé \\ndes contraintes ou exercé des pressions de toutes natures sur ce salarié. Aucun salarié, aucune personne en formation ou en stag e ne peut être \\nsanctionné ni licencié pour avoir témoigné des agissements définis à l'alinéa \\nprécédent ou pour les avoir relatés. Nul ne peut prendre en considération le fait que la personne intéressée a refusé \\nde subir les agissements de harcèlement ou q u'une personne témoin les a relatés, \\npour décider, notamment en matière d'embauche, de rémunération, de formation, \\nd'affectation, de qualification, de classification, de promotion professionnelle, de \\nmutation, de résiliation, de renouvellement de contrat d e travail ou de sanctions \\ndisciplinaire. Constituent un harcèlement sexuel les comportements abusifs, les menaces, les \\nattaques, les paroles, les intimidations, les écrits, les attitudes ; les agissements \\nrépétés à l'encontre d'un salarié, ayant une connot ation sexuelle, dont le but est \\nd'obtenir des faveurs de nature sexuelle à son profil ou au profit d'un tiers. Constituent un harcèlement moral les comportements abusifs, les menaces, les \\nattaques, les paroles, les intimidations, les écrits, les attitudes,  les agissements \\nrépétés à l'encontre d'un salarié, ayant pour objet ou pour effet la dégradation de ses \\nconditions de travail et qui comme tels sont susceptibles de porter atteinte à ses \\ndroits et a sa dignité, d'altérer sa santé physique ou mentale ou de compromettre son \\navenir professionnel. Le harcèlement se prouve par tous moyens.\"),\n",
       " Document(metadata={'id': 0, 'relevance_score': np.float32(0.99953455), 'pageno': 43, 'source': 'sample/Le-code-du-travail-ivoirien-2023.pdf', '_id': '0f46da51-bf4c-4a9e-9384-48c124e9ea28', '_collection_name': 'labor_law'}, page_content=\"4\\n4 \\n \\nArt. 17.4 \\nLe motif du licenciement peut tenir à la personne du salarié, qu'il s'agisse de son \\nétat de santé, de son aptitude à tenir l'emploi, de son insuffisance professionnelle ou \\nde sa conduite fautive. Le licenciement est alors qualifié de licenciement pour motif \\npersonnel. L'employeur qui licencie pour motif personnel doit notifier sa décision par \\nécrit au salarié. La lettre de licenciement comporte nécessairement : \\n- l'indication du ou des motifs de la rupture ; \\n- le nom ou la raison sociale de l'employeur ; \\n- le numéro d'immatriculation à l'institution de Prévoyance sociale et l'adresse de \\nl'employeur ; \\n- les noms, prénoms, numéro d'affiliation à l'Institution de prévoyance sociale, date \\nd'embauche et qualification professionnelle du salarié licencié ; \\n- la date de prise d'effet de la rupture. Dans le même temps où il notifie le licenciement au salarié, l'employeur \\ninforme l'inspecteur du travail et des lois sociales du ressort. Cette information \\nécrite co mporte les mêmes indications que celles contenues dans la lettre de \\nlicenciement.\"),\n",
       " Document(metadata={'id': 14, 'relevance_score': np.float32(0.99940294), 'pageno': 457, 'source': 'sample/Le-code-du-travail-ivoirien-2023.pdf', '_id': '5dc8fe41-d72a-42f8-89fe-2ba2edfc3e9d', '_collection_name': 'labor_law'}, page_content=\"4\\n5\\n8 \\n \\nLa non observation de cette procédure rend nulle la décision de licenciement \\ncollectif et les travailleurs licenciés doivent être réintégrés d ans leur emploi avec \\npaiement de leur salaire pendant la période de la suspension du contrat (9) \\nLorsque le licenciement collectif est opéré dans la forme prévue par la présente    \\nconvention (les articles 16.7 du Code du Travail), les travailleurs licenci és \\nbénéficieront d'une priorité de réembauchage dans les conditions prévues au 6e \\nalinéa de l'article 13 de la présente convention. ARTICLE 39 \\nINDEMNITE DE LICENCIEMENT \\nEn cas de licenciement par l'employeur, le travailleur ayant accompli dans \\nl'entreprise une durée de service au moins égale à la période de  référence ouvrant \\ndroit de jouissance au congé telle que fixée par la réglementation en vigueur, a \\ndroit à une indemnité de licenciement distincte de l'indemnité compensatrice de \\npréavis conformément à l'article 42 du Code du Travail (Lire article 16.12 ). Les travailleurs sont admis au bénéfice de l'indemnité de licenciement lorsqu'ils \\natteignent la durée de présence nécessaire à son attribution à la suite de plusieurs \\nembauches dans la même entreprise si leurs départs précédents ont été provoqués \\npar une compression d'effectifs ou une suppression d'emplois. Dans ce cas, le montant de l'indemnité de licenciement est déterminé déduction \\nfaite des sommes qui ont pu être versées à ce titre lors des licenci ements \\nantérieurs. Cette indemnité est représentée, pour chaque année de présence accomplie dans \\nl'entreprise, par un pourcentage déterminé du salaire global mensuel moyen de \\ndouze mois d'activité qui ont précédé la date de licenciement. On entend par salaire global toutes les prestations constituant une contrepartie du \\ntravail à l'exclusion de celles présentant le caractère d'un remboursement de frais. Le, pourcentage est fixé à : \\n 30 % pour les 5 premières années ; \\n 35 % pour la période allant de la 6e à la 10e année, incluse ; \\n 40 % pour la période s'étendant au-delà de la 10e année.\")]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = hybrid_search(\"quelles sont les conditions nécessaires pour qu'un employeur puisse légalement licencier un salarié ?\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094354e5",
   "metadata": {},
   "source": [
    "## CONTEXT MANAGEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46756a",
   "metadata": {},
   "source": [
    "### OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8baf6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "ollama_llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f522f73d",
   "metadata": {},
   "source": [
    "### HYBRID RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03edf8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "def custom_retriever(query: str):\n",
    "    # You can adjust top_k here if needed\n",
    "    return hybrid_search(query, top_k=20)\n",
    "\n",
    "# Format manually as a string prompt\n",
    "template = \"\"\"\n",
    "**Role**\n",
    "    - you are a helpful assistant and your role is to to answer questions from user.\n",
    "**Objective** \n",
    "    - you'll be given documents to use as source for your answer. \n",
    "    - be as faithfull as possible to them.\n",
    "**Expected solution**\n",
    "    - a clear and well formated answer with three parts: answer, explication and source.\n",
    "    \n",
    "question : {question}\n",
    "context : {context}\n",
    "reponse :\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": RunnableLambda(custom_retriever) | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | ollama_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f03af35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/labor_law/points/query \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = qa_chain.invoke(\"quelles sont les conditions nécessaires pour qu'un employeur puisse légalement licencier un salarié ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5986887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Réponse**\n",
       "\n",
       "L'employeur peut légalement licencier un salarié sous certaines conditions. Selon l'article 17.4 du Code du Travail, le motif du licenciement peut tenir à la personne du salarié, qu'il s'agisse de son état de santé, de son aptitude à tenir l'emploi, de son insuffisance professionnelle ou de sa conduite fautive.\n",
       "\n",
       "**Explication**\n",
       "\n",
       "L'article 17.4 précise que le licenciement peut être motivé par des raisons personnelles, telles que les problèmes de santé ou les difficultés professionnelles. Cependant, il est important de noter que l'employeur doit respecter certaines formalités pour justifier le licenciement, notamment la notification écrite au salarié et à l'inspecteur du travail.\n",
       "\n",
       "**Source**\n",
       "\n",
       "* Article 17.4 du Code du Travail : \"Le motif du licenciement peut tenir à la personne du salarié, qu'il s'agisse de son état de santé, de son aptitude à tenir l'emploi, de son insuffisance professionnelle ou de sa conduite fautive.\"\n",
       "* Article 39 du Code du Travail : \"En cas de licenciement par l'employeur, le travailleur ayant accompli dans l'entreprise une durée de service au moins égale à la période de référence ouvrant droit de jouissance au congé tel que fixée par la réglementation en vigueur, a droit à une indemnité de licenciement distincte de l'indemnité compensatrice de préavis.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f1fe2f",
   "metadata": {},
   "source": [
    "### HYBRID RETRIEVAL WITH CACHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56603d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0].metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e722252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6382e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     \"source\": docs[0].metadata['source'],\n",
    "#     \"content\" : docs[0].page_content\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01966da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First question ===\n",
      "✗ Cache MISS (0 hits, 1 misses)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/labor_law/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cache size: 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time : 25.622926399999415\n",
      "**Réponse**\n",
      "\n",
      "**Answer**\n",
      "Les différents types de contrat de travail sont :\n",
      "\n",
      "*   Contrat à durée indéterminée (CDI) : il est précédé d'un engagement à l'essai ou peut comporter une clause d'élimination d'une période d'essai avant l'engagement définitif.\n",
      "*   Contrat à temps partiel : il est précédé d'un engagement à l'essai ou peut comporter une clause d'élimination d'une période d'essai avant l'engagement définitif.\n",
      "*   Contrat temporaire : il est précédé d'un engagement à l'essai ou peut comporter une clause d'élimination d'une période d'essai avant l'engagement définitif.\n",
      "\n",
      "**Explication**\n",
      "Selon l'article 2 du code du travail ivoirien de 2023, le contrat de travail doit comporter les mentions suivantes : la date et le lieu d'établissement du contrat ; les nom, prénoms, profession et domicile de l'employeur ; les nom, prénoms, sexe, date et lieu de naissance, la filiation, le domicile et la nationalité du travailleur, son métier ou sa profession; la nature et la durée du contrat ; le classement du travailleur dans la hiérarchie professionnelle, son salaire et les accessoires du salaire ; le ou les emplois que le travailleur sera appelé à tenir dans l'entreprise ou ses établissements implantés en Côte d'Ivoire ; la référence aux textes réglementaires ou aux conventions collectives qui régissent l'ensemble des rapports entre employeur et travailleur ; éventuellement, les clauses particulières convenues entre les Parties.\n",
      "\n",
      "Selon l'article 10 du code du travail ivoirien de 2023, les jeunes travailleurs sont des personnes de moins de dix-huit ans mais qui ont atteint l'âge de quatorze ans requis pour l'admission à l'emploi ou pour le travail. Selon l'article 11 du code du travail ivoirien de 2023, la traite d'enfants s'entend de tout acte de recrutement, de transport, de transfert, d'hébergement, ou d'accueil d'enfants à l'intérieur ou à l'extérieur d'un pays, aux fins d'exploitation quels que soient les moyens utilisés.\n",
      "\n",
      "**Source**\n",
      "\n",
      "*   Le code du travail ivoirien de 2023\n",
      "    *   Article 2 : Les mentions suivantes doivent être contenues dans le contrat de travail.\n",
      "    *   Article 10 : Les jeunes travailleurs sont des personnes de moins de dix-huit ans mais qui ont atteint l'âge de quatorze ans requis pour l'admission à l'emploi ou pour le travail.\n",
      "    *   Article 11 : La traite d'enfants s'entend de tout acte de recrutement, de transport, de transfert, d'hébergement, ou d'accueil d'enfants à l'intérieur ou à l'extérieur d'un pays, aux fins d'exploitation quels que soient les moyens utilisés.\n",
      "\n",
      "=== Similar question (should hit cache) ===\n",
      "✓ Cache HIT (1 hits, 1 misses)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time : 4.045568899993668\n",
      "**Réponse**\n",
      "\n",
      "**Answer**\n",
      "Les différents types de contrat de travail en Côte d'Ivoire sont :\n",
      "\n",
      "*   Contrat de travail précédé d'un engagement à l'essai\n",
      "*   Contrat de travail avec une clause d'élimination d'une période d'essai\n",
      "*   Contrat de travail pour les jeunes travailleurs (personnes de moins de 18 ans mais ayant atteint 14 ans)\n",
      "\n",
      "**Explication**\n",
      "Selon l'article 2 du Code du Travail Ivoirien, le contrat de travail doit comporter certaines mentions, notamment la date et le lieu d'établissement, les informations sur l'employeur et le travailleur, ainsi que la nature et la durée du contrat. L'article 10 précise que les jeunes travailleurs sont des personnes de moins de 18 ans mais ayant atteint 14 ans.\n",
      "\n",
      "L'article 11 définit la traite d'enfants comme tout acte de recrutement, de transport, de transfert, d'hébergement ou d'accueil d'enfants à l'intérieur ou à l'extérieur d'un pays, aux fins d'exploitation.\n",
      "\n",
      "**Source**\n",
      "*   Article 2 du Code du Travail Ivoirien (Le-code-du-travail-ivoirien-2023.pdf)\n",
      "*   Article 10 et 11 du Code du Travail Ivoirien (Le-code-du-travail-ivoirien-2023.pdf)\n",
      "\n",
      "=== Different question (should miss cache) ===\n",
      "✗ Cache MISS (1 hits, 2 misses)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/labor_law/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cache size: 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time : 8.707784400001401\n",
      "**Réponse**\n",
      "\n",
      "**Answer**\n",
      "La durée maximale d'un stage est de 12 mois, renouvellements compris.\n",
      "\n",
      "**Explication**\n",
      "Selon l'article 13.14 du Code du travail ivoirien de 2023, le contrat de stage de qualification ou d'expérience professionnelle ne peut excéder une durée de douze mois, renouvellements compris. Cela signifie que les entreprises sont tenues à donner au stagiaire une formation pratique pour acquérir une qualification ou une expérience professionnelle pendant cette période.\n",
      "\n",
      "**Source**\n",
      "Le Code du travail ivoirien de 2023, article 13.14 et article 14.5.\n",
      "\n",
      "=== Cache Statistics ===\n",
      "Total hits: 1\n",
      "Total misses: 2\n",
      "Hit rate: 33.3%\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "# Initialize cache\n",
    "class LimitedSemanticCache:\n",
    "    def __init__(self, max_size=100, similarity_threshold=0.80):\n",
    "        self.cache = OrderedDict()\n",
    "        self.max_size = max_size\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.embeddings = embedding_model\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def get(self, query: str):\n",
    "        \"\"\"Get cached result if similar query exists.\"\"\"\n",
    "        query_embedding = self.embeddings.embed_query(query)\n",
    "        \n",
    "        for cached_query, cached_data in self.cache.items():\n",
    "            similarity = np.dot(query_embedding, cached_data[\"embedding\"]) / (\n",
    "                np.linalg.norm(query_embedding) * np.linalg.norm(cached_data[\"embedding\"]) + 1e-10\n",
    "            )\n",
    "            if similarity >= self.similarity_threshold:\n",
    "                self.hits += 1\n",
    "                print(f\"✓ Cache HIT ({self.hits} hits, {self.misses} misses)\")\n",
    "                return cached_data[\"results\"]\n",
    "        \n",
    "        self.misses += 1\n",
    "        print(f\"✗ Cache MISS ({self.hits} hits, {self.misses} misses)\")\n",
    "        return None\n",
    "    \n",
    "    def put(self, query: str, results, embedding):\n",
    "        \"\"\"Add to cache, evicting oldest entry if full.\"\"\"\n",
    "        if len(self.cache) >= self.max_size:\n",
    "            removed = self.cache.popitem(last=False)\n",
    "            print(f\"  Cache evicted oldest query: '{removed[0][:30]}...'\")\n",
    "        \n",
    "        self.cache[query] = {\"embedding\": embedding, \"results\": results}\n",
    "        print(f\"  Cache size: {len(self.cache)}/{self.max_size}\")\n",
    "\n",
    "# Initialize cache instance\n",
    "cache = LimitedSemanticCache(max_size=100, similarity_threshold=0.80)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    formatted = []\n",
    "    for d in docs:\n",
    "        obj = {\n",
    "            \"source\": d.metadata.get(\"source\"),\n",
    "            \"content\": d.page_content\n",
    "        }\n",
    "        formatted.append(json.dumps(obj, ensure_ascii=False, indent=2))\n",
    "    return \"\\n\\n\".join(formatted)\n",
    "\n",
    "def cached_retriever(query: str):\n",
    "    \"\"\"Retriever with semantic caching.\"\"\"\n",
    "    # Check cache first\n",
    "    cached_results = cache.get(query)\n",
    "    if cached_results:\n",
    "        return cached_results\n",
    "    \n",
    "    # Cache miss: retrieve and store\n",
    "    results = hybrid_search(query, top_k=20)\n",
    "    query_embedding = cache.embeddings.embed_query(query)\n",
    "    cache.put(query, results, query_embedding)\n",
    "    \n",
    "    return results\n",
    "\n",
    "template = \"\"\"\n",
    "**Role**\n",
    "    - you are a helpful assistant and your role is to to answer questions from user.\n",
    "**Objective** \n",
    "    - you'll be given documents to use as source for your answer. \n",
    "    - be as faithfull as possible to them.\n",
    "**Expected solution**\n",
    "    - a clear and well formated answer with three parts: answer, explication and source.\n",
    "    \n",
    "question : {question}\n",
    "context : {context}\n",
    "reponse :\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "# Build the chain with cached retriever\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": RunnableLambda(cached_retriever) | RunnableLambda(format_docs),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | ollama_llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it\n",
    "print(\"=== First question ===\")\n",
    "start_time = time.perf_counter()\n",
    "result1 = qa_chain.invoke(\"quels sont les diffents types de contrat de travail ?\")\n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"execution time : {execution_time}\")\n",
    "print(result1)\n",
    "\n",
    "print(\"\\n=== Similar question (should hit cache) ===\")\n",
    "start_time = time.perf_counter()\n",
    "result2 = qa_chain.invoke(\"les differents types de contrat de travail\")\n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"execution time : {execution_time}\")\n",
    "print(result2)\n",
    "\n",
    "print(\"\\n=== Different question (should miss cache) ===\")\n",
    "start_time = time.perf_counter()\n",
    "result3 = qa_chain.invoke(\"quelle est la durée maximale d'un stage ?\")\n",
    "end_time = time.perf_counter()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"execution time : {execution_time}\")\n",
    "print(result3)\n",
    "\n",
    "# Check stats\n",
    "print(f\"\\n=== Cache Statistics ===\")\n",
    "print(f\"Total hits: {cache.hits}\")\n",
    "print(f\"Total misses: {cache.misses}\")\n",
    "print(f\"Hit rate: {cache.hits / (cache.hits + cache.misses) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced1258",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44225b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
